[
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home_Ex02 - VAST Challenge 2025 - Mini Challenge 3",
    "section": "",
    "text": "Clepper Jessen, an investigative journalist, is probing potential corruption in Oceanus following the temporary closure of Nemo Reef and the shadowy arrival of pop star Sailor Shift. A knowledge graph constructed from intercepted radio communications offers a detailed map of interactions between people and vessels over the past two weeks. By analyzing these communications — who talks to whom and about what — this report aims to uncover key social groupings, identify individuals using pseudonyms, and uncover hidden networks that may be linked to corruption to support the investigation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-knowledge-graph-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#importing-knowledge-graph-data",
    "title": "Take-home_Ex02 - VAST Challenge 2025 - Mini Challenge 3",
    "section": "4.1 Importing Knowledge Graph Data",
    "text": "4.1 Importing Knowledge Graph Data\nWe begin by loading the raw knowledge graph and its schema using the jsonlite package. The main data file (MC3_graph.json) contains two primary components: nodes and edges, which represent entities and their interactions. The accompanying schema file (MC3_schema.json) provides structural metadata that helps us understand the types and attributes of each node and edge in the graph.\n\ngraph_data &lt;- fromJSON(\"data/MC3_graph.json\")\nschema_data &lt;- fromJSON(\"data/MC3_schema.json\")\n\nThese files form the foundation for all subsequent data wrangling and analysis. In the next steps, we will explore their structure and extract relevant features to support our investigation into entity relationships and pseudonym usage."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#inspecting-knowledge-graph-structure",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#inspecting-knowledge-graph-structure",
    "title": "Take-home_Ex02 - VAST Challenge 2025 - Mini Challenge 3",
    "section": "4.2 Inspecting Knowledge Graph Structure",
    "text": "4.2 Inspecting Knowledge Graph Structure\nBefore proceeding with data wrangling, we first inspect the structure of the knowledge graph using glimpse() to understand the overall layout of nodes and edges.\n\nglimpse(graph_data)\n\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame': 1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':   1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame': 3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n\nglimpse(schema_data)\n\nList of 1\n $ schema:List of 2\n  ..$ nodes:List of 3\n  .. ..$ Entity      :List of 2\n  .. ..$ Event       :List of 2\n  .. ..$ Relationship:List of 2\n  ..$ edges:List of 3\n  .. ..$ description: chr \"Connections between nodes in the knowledge graph\"\n  .. ..$ is_inferred: chr \"bool\"\n  .. ..$ types      :'data.frame':  6 obs. of  5 variables:\n\n\nThe graph structure contains:\n\n1159 nodes, each representing an entity, event, or relationship (Unlike traditional network graphs where nodes represent only entities and edges represent relationships, the VAST Challenge MC3 knowledge graph treats relationships as nodes too.)\n3226 edges, which describe the connections between these nodes\nNodes vary by type and sub_type, and contain attributes such as label, name, and a large number of optional fields (e.g., timestamp, content, assessment_type) depending on the node’s sub_type\n\nThe schema file describes the expected structure and data types for each node and edge type. It confirms that the dataset follows a consistent schema, but many fields are sparse due to their relevance only to specific node types.\nSome observations are:\n\nThe dataset contains a large number of attributes, but most are sparsely populated, which is expected, as different node types carry different metadata.\nCommunication Event nodes are of particular interest for this analysis, as they contain the message content and timestamps—crucial for exploring interaction patterns, associated groups, and pseudonym usage.\nMany names appear under label and name fields, including potential aliases. These will need to be cross-checked and standardized for accurate network mapping.\n\nWe will also need to clean and enrich the data by:\n\nConverting timestamp fields to datetime\nIsolating sender-receiver relationships\nLinking communication content back to referenced entities (e.g., vessels or pseudonyms mentioned)\n\nThese steps are foundational for tracing communication & relationships, uncovering social groups, and identifying pseudonym patterns—all central to answering Questions 2 and 3."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#extracting-the-edges-and-nodes-tables",
    "title": "Take-home_Ex02 - VAST Challenge 2025 - Mini Challenge 3",
    "section": "4.3 Extracting the Edges and Nodes Tables",
    "text": "4.3 Extracting the Edges and Nodes Tables\nTo prepare for further analysis, we extract the graph’s nodes and edges components into tidy tibbles. This allows us to explore, filter, and join the data more efficiently using dplyr and tidyverse tools.\n\nnodes_tbl &lt;- as_tibble(graph_data$nodes)\nedges_tbl &lt;- as_tibble(graph_data$edges)\n\nhead(nodes_tbl)\n\n# A tibble: 6 × 31\n  type   label   name  sub_type id    timestamp monitoring_type findings content\n  &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;  \n1 Entity Sam     Sam   Person   Sam   &lt;NA&gt;      &lt;NA&gt;            &lt;NA&gt;     &lt;NA&gt;   \n2 Entity Kelly   Kelly Person   Kelly &lt;NA&gt;      &lt;NA&gt;            &lt;NA&gt;     &lt;NA&gt;   \n3 Entity Nadia … Nadi… Person   Nadi… &lt;NA&gt;      &lt;NA&gt;            &lt;NA&gt;     &lt;NA&gt;   \n4 Entity Elise   Elise Person   Elise &lt;NA&gt;      &lt;NA&gt;            &lt;NA&gt;     &lt;NA&gt;   \n5 Entity Liam T… Liam… Person   Liam… &lt;NA&gt;      &lt;NA&gt;            &lt;NA&gt;     &lt;NA&gt;   \n6 Entity Samant… Sama… Person   Sama… &lt;NA&gt;      &lt;NA&gt;            &lt;NA&gt;     &lt;NA&gt;   \n# ℹ 22 more variables: assessment_type &lt;chr&gt;, results &lt;chr&gt;,\n#   movement_type &lt;chr&gt;, destination &lt;chr&gt;, enforcement_type &lt;chr&gt;,\n#   outcome &lt;chr&gt;, activity_type &lt;chr&gt;, participants &lt;int&gt;,\n#   thing_collected &lt;df[,2]&gt;, reference &lt;chr&gt;, date &lt;chr&gt;, time &lt;chr&gt;,\n#   friendship_type &lt;chr&gt;, permission_type &lt;chr&gt;, start_date &lt;chr&gt;,\n#   end_date &lt;chr&gt;, report_type &lt;chr&gt;, submission_date &lt;chr&gt;,\n#   jurisdiction_type &lt;chr&gt;, authority_level &lt;chr&gt;, coordination_type &lt;chr&gt;, …\n\nhead(edges_tbl)\n\n# A tibble: 6 × 5\n  id    is_inferred source target                      type \n  &lt;chr&gt; &lt;lgl&gt;       &lt;chr&gt;  &lt;chr&gt;                       &lt;chr&gt;\n1 2     TRUE        Sam    Relationship_Suspicious_217 &lt;NA&gt; \n2 3     FALSE       Sam    Event_Communication_370     sent \n3 5     TRUE        Sam    Event_Assessment_600        &lt;NA&gt; \n4 3013  TRUE        Sam    Relationship_Colleagues_430 &lt;NA&gt; \n5 &lt;NA&gt;  TRUE        Sam    Relationship_Friends_272    &lt;NA&gt; \n6 &lt;NA&gt;  TRUE        Sam    Relationship_Colleagues_215 &lt;NA&gt; \n\n\nThe nodes_tbl contains 1,159 rows and 31 columns, including attributes like type, label, sub_type, and content. Meanwhile, the edges_tbl captures 3,226 connections among these nodes, indicating the flow of communication or relationships via source, target, and type.\nTo understand the distribution of node types, we generate a quick summary:\n\ntable(nodes_tbl$type)\n\n\n      Entity        Event Relationship \n          72          802          285 \n\n\nMost nodes represent Events, which includes communication, assessments, and movements. These are the core of the graph’s activity and will be our main focus moving forward. The remaining nodes represent Relationships (such as colleagues) and Entities (such as people and vessels).\nThis breakdown helps guide our filtering in the next steps—particularly in isolating Communication Events and linking them to relevant people, vessels, and aliases for Questions 2 and 3."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#initial-eda",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#initial-eda",
    "title": "Take-home_Ex02 - VAST Challenge 2025 - Mini Challenge 3",
    "section": "4.4 Initial EDA",
    "text": "4.4 Initial EDA\nTo better understand the characteristics of the dataset, we use the ExpCatViz() function from the SmartEDA package to examine the distribution of key categorical variables within nodes_tbl.\n\nExpCatViz(data = nodes_tbl, col = \"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\n\n[[7]]\n\n\n\n\n\n\n\n\n\n\n[[8]]\n\n\n\n\n\n\n\n\n\n\n[[9]]\n\n\n\n\n\n\n\n\n\n\n[[10]]\n\n\n\n\n\n\n\n\n\n\n[[11]]\n\n\n\n\n\n\n\n\n\n\n[[12]]\n\n\n\n\n\n\n\n\n\n\n[[13]]\n\n\n\n\n\n\n\n\n\n\n[[14]]\n\n\n\n\n\n\n\n\n\nThis reveals several useful insights:\n\nThe majority of nodes are of type Event (69%), followed by Relationship (25%) and Entity (6%). This confirms that the dataset is heavily event-driven, reinforcing the need to filter and analyze communication-related events in depth.\nMost of the categorical fields—such as monitoring_type, assessment_type, movement_type, and enforcement_type—are overwhelmingly sparse, with over 90% of values marked as NA. These attributes are subtype-specific and not useful for broad filtering.\nVariables like activity_type, reference, date, and time show close to 100% missingness, suggesting they were either not captured in the graph or only used in a few isolated node types.\nThese early signals reinforce the idea that the most promising and information-rich nodes for analysis are Communication Event nodes, which are expected to contain fields like content, timestamp, and be connected to both people and vessels.\n\nTo complement our earlier inspection of node attributes, we examine the categorical distribution in the edges_tbl using ExpCatViz().\n\nExpCatViz(data = edges_tbl, col = \"lightblue\")\n\n[[1]]\n\n\n\n\n\n\n\n\n\nThis reveals the breakdown of type within the edges:\n\nThe two most frequent edge types are evidence_for (32%) and NA (also 32%). The former indicates that a communication or event node is cited as evidence for another node (typically a relationship or event).\nsent and received edges each make up 18% of the total. These are especially important for identifying the flow of communication — i.e., who is sending and who is receiving messages — which will directly support Q2a (interactions) and Q3a (pseudonym tracking).\nA large number of edge types are marked as NA, which may indicate either missing labels or simple links between nodes (such as connecting a person to a vessel) that don’t fall under a specific relationship category.\n\nThis insight confirms that sent and received edges are essential for reconstructing directed communication paths, while evidence_for edges can later help establish which events support known relationships — a detail that may be helpful in identifying aliases."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-cleaning-and-wrangling",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-cleaning-and-wrangling",
    "title": "Take-home_Ex02 - VAST Challenge 2025 - Mini Challenge 3",
    "section": "4.5 Data Cleaning and Wrangling",
    "text": "4.5 Data Cleaning and Wrangling\nTo analyze interaction & relationships, recognize groups, and identify pseudonym usage, we perform a series of data cleaning and wrangling steps. These steps will allow us to isolate communication events, trace sender–receiver interactions, and prepare a clean dataset for visual exploration.\nThe main data preparation steps include:\n\nExtracting communication events with timestamps\nCleaning and formatting timestamp data\nIdentifying sender and receiver relationships\nJoining sender-receiver pairs to their respective names\nMerging all relevant fields into a single tidy dataframe for analysis\nSaving the cleaned dataset for reuse in subsequent sections\n\n\n4.5.1 Extracting Communication Events With Timestamps\nThe first step filters out all non-communication events. We focus only on nodes of type == \"Event\" and sub_type == \"Communication\", as these contain the actual messages exchanged between people and vessels.\n\ncomm_events &lt;- nodes_tbl %&gt;%\n  filter(type == \"Event\", sub_type == \"Communication\")\n\nhead(comm_events)\n\n# A tibble: 6 × 31\n  type  label    name  sub_type id    timestamp monitoring_type findings content\n  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;           &lt;chr&gt;    &lt;chr&gt;  \n1 Event Communi… &lt;NA&gt;  Communi… Even… 2040-10-… &lt;NA&gt;            &lt;NA&gt;     Hey Th…\n2 Event Communi… &lt;NA&gt;  Communi… Even… 2040-10-… &lt;NA&gt;            &lt;NA&gt;     Hey Th…\n3 Event Communi… &lt;NA&gt;  Communi… Even… 2040-10-… &lt;NA&gt;            &lt;NA&gt;     Sam, i…\n4 Event Communi… &lt;NA&gt;  Communi… Even… 2040-10-… &lt;NA&gt;            &lt;NA&gt;     Mrs. M…\n5 Event Communi… &lt;NA&gt;  Communi… Even… 2040-10-… &lt;NA&gt;            &lt;NA&gt;     Boss, …\n6 Event Communi… &lt;NA&gt;  Communi… Even… 2040-10-… &lt;NA&gt;            &lt;NA&gt;     Mrs. M…\n# ℹ 22 more variables: assessment_type &lt;chr&gt;, results &lt;chr&gt;,\n#   movement_type &lt;chr&gt;, destination &lt;chr&gt;, enforcement_type &lt;chr&gt;,\n#   outcome &lt;chr&gt;, activity_type &lt;chr&gt;, participants &lt;int&gt;,\n#   thing_collected &lt;df[,2]&gt;, reference &lt;chr&gt;, date &lt;chr&gt;, time &lt;chr&gt;,\n#   friendship_type &lt;chr&gt;, permission_type &lt;chr&gt;, start_date &lt;chr&gt;,\n#   end_date &lt;chr&gt;, report_type &lt;chr&gt;, submission_date &lt;chr&gt;,\n#   jurisdiction_type &lt;chr&gt;, authority_level &lt;chr&gt;, coordination_type &lt;chr&gt;, …\n\n\nThis gives us a subset of nodes that represent intercepted communications. These records include message content, associated timestamps, and unique IDs that can be matched to senders, receivers, and evidence links.\n\n\n4.5.2 Extract Necessary Fields\nTo prepare for linking communication events with sender and receiver nodes, we extract only the essential attributes:\n\nid: unique identifier of each communication event node\ntimestamp: the time the message was recorded\ncontent: the message text, which may contain names, pseudonyms, or references to vessels\n\n\ncomm_events &lt;- comm_events %&gt;%\n  select(id, timestamp = timestamp, content = content)\n\nhead(comm_events)\n\n# A tibble: 6 × 3\n  id                    timestamp           content                             \n  &lt;chr&gt;                 &lt;chr&gt;               &lt;chr&gt;                               \n1 Event_Communication_1 2040-10-01 08:09:00 Hey The Intern, it's The Lookout! J…\n2 Event_Communication_2 2040-10-01 08:10:00 Hey The Lookout, The Intern here! I…\n3 Event_Communication_3 2040-10-01 08:13:00 Sam, it's Kelly! Let's meet at Sunr…\n4 Event_Communication_5 2040-10-01 08:16:00 Mrs. Money, it's The Intern. Just c…\n5 Event_Communication_6 2040-10-01 08:19:00 Boss, it's Mrs. Money. I've reviewe…\n6 Event_Communication_7 2040-10-01 08:21:00 Mrs. Money, this is Boss. I'm avail…\n\n\nThis step gives us a concise working table with only the fields required for further merging and text analysis. The content column will be particularly important for detecting pseudonyms and identifying entities mentioned in the communication — both of which are key to answering Q2b and Q3a.\nIn the next step, we’ll clean and standardize the timestamp to support time-based grouping and visualizations.\n\n\n4.5.3 Convert Timestamp from Character to Datetime Format\nThe timestamp field was originally stored as a character string. To enable time-based filtering, aggregation, and visualizations, we convert it to proper datetime format using ymd_hms() from the lubridate package.\n\ncomm_events &lt;- comm_events %&gt;%\n  mutate(timestamp = ymd_hms(timestamp))\n\nhead(comm_events)\n\n# A tibble: 6 × 3\n  id                    timestamp           content                             \n  &lt;chr&gt;                 &lt;dttm&gt;              &lt;chr&gt;                               \n1 Event_Communication_1 2040-10-01 08:09:00 Hey The Intern, it's The Lookout! J…\n2 Event_Communication_2 2040-10-01 08:10:00 Hey The Lookout, The Intern here! I…\n3 Event_Communication_3 2040-10-01 08:13:00 Sam, it's Kelly! Let's meet at Sunr…\n4 Event_Communication_5 2040-10-01 08:16:00 Mrs. Money, it's The Intern. Just c…\n5 Event_Communication_6 2040-10-01 08:19:00 Boss, it's Mrs. Money. I've reviewe…\n6 Event_Communication_7 2040-10-01 08:21:00 Mrs. Money, this is Boss. I'm avail…\n\n\nThis transformation ensures that the timestamp column is now recognized as a POSIXct object (), allowing us to later group communications by hour, day, or time interval.\nNext, we’ll move on to identifying sender and receiver connections by working with the edges_tbl.\n\n\n4.5.4 Filter Edges for Sender and Receiver\nTo identify who is sending and receiving each message, we filter the edges_tbl to retain only edges of type “sent” or “received”. These indicate a directional connection between an entity (usually a person) and a communication event.\n\ncomm_edges &lt;- edges_tbl %&gt;%\n  filter(type %in% c(\"sent\", \"received\")) %&gt;%\n  select(source, target, type)\n\nhead(comm_edges)\n\n# A tibble: 6 × 3\n  source      target                  type \n  &lt;chr&gt;       &lt;chr&gt;                   &lt;chr&gt;\n1 Sam         Event_Communication_370 sent \n2 Kelly       Event_Communication_3   sent \n3 Kelly       Event_Communication_443 sent \n4 Nadia Conti Event_Communication_331 sent \n5 Nadia Conti Event_Communication_334 sent \n6 Nadia Conti Event_Communication_529 sent \n\n\nIn this structure:\n\nThe source column contains the person or entity initiating the edge\nThe target column refers to the communication event\nThe type column tells us whether this is a sent or received connection\n\nThis step is crucial for establishing sender–receiver pairs in later stages. By reshaping and joining this filtered edge list, we’ll be able to reconstruct the full communication path between individuals — a core component of answering Q2a (interaction mapping) and Q3a (alias tracking).\nNext, we’ll reshape this into a wide format with both sender and receiver in the same row.\n\n\n4.5.5 Separate and Rename\nNext, we break down the filtered comm_edges into two separate tables: one for senders and one for receivers. This step allows us to later combine both perspectives of each communication into a single row.\n\nsenders &lt;- comm_edges %&gt;%\n  filter(type == \"sent\") %&gt;%\n  rename(sender = source, message_id = target)\n\nreceivers &lt;- comm_edges %&gt;%\n  filter(type == \"received\") %&gt;%\n  rename(receiver = target, message_id = source)\n\n\nIn the senders table, we treat the source as the person sending the message and the target as the message node (message_id)\nIn the receivers table, we flip that: the target is the receiver and the source is the message_id\n\nBy renaming columns consistently, we can later join both tables using the shared message_id, giving us a clean structure of:\nmessage_id | sender | receiver\nThis format is key to visualizing direct interactions between individuals and spotting recurring patterns in communication and alias usage.\n\n\n4.5.6 Join Sender and Receiver Info\nNow that we have isolated senders and receivers, we join the two datasets using message_id to form a complete sender–receiver pair for each communication event.\n\ncomm_pairs &lt;- inner_join(senders, receivers, by = \"message_id\")\nhead(comm_pairs)\n\n# A tibble: 6 × 5\n  sender      message_id              type.x receiver             type.y  \n  &lt;chr&gt;       &lt;chr&gt;                   &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;   \n1 Sam         Event_Communication_370 sent   Kelly                received\n2 Kelly       Event_Communication_3   sent   Sam                  received\n3 Kelly       Event_Communication_443 sent   Sam                  received\n4 Nadia Conti Event_Communication_331 sent   Haacklee Harbor      received\n5 Nadia Conti Event_Communication_334 sent   Oceanus City Council received\n6 Nadia Conti Event_Communication_529 sent   Liam Thorne          received\n\n\nThe resulting dataframe gives us one row per message, including:\n\nsender and receiver names\nThe corresponding message_id\nEdge types (sent, received) — useful for validating directionality if needed\n\nThis structure is foundational for building a person-to-person interaction network, detecting frequent communication pairs, and identifying clusters of closely associated individuals (Q2b). It also enables us to trace who may be using pseudonyms across multiple interactions (Q3a).\nIn the next step, we’ll enrich this structure by joining with the actual communication content and timestamps.\n\n\n4.5.7 Combine with Communication Details\nTo complete the communication record, we join the sender–receiver pairs with the original message content and timestamps. This creates a single tidy dataset that combines who spoke to whom, when, and what was said.\n\ncomm_full &lt;- comm_pairs %&gt;%\n  left_join(comm_events, by = c(\"message_id\" = \"id\"))\n\nhead(comm_full)\n\n# A tibble: 6 × 7\n  sender      message_id      type.x receiver type.y timestamp           content\n  &lt;chr&gt;       &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;  &lt;dttm&gt;              &lt;chr&gt;  \n1 Sam         Event_Communic… sent   Kelly    recei… 2040-10-05 10:48:00 Hey Ke…\n2 Kelly       Event_Communic… sent   Sam      recei… 2040-10-01 08:13:00 Sam, i…\n3 Kelly       Event_Communic… sent   Sam      recei… 2040-10-07 08:11:00 Hey Sa…\n4 Nadia Conti Event_Communic… sent   Haackle… recei… 2040-10-05 09:45:00 Haackl…\n5 Nadia Conti Event_Communic… sent   Oceanus… recei… 2040-10-05 09:49:00 This i…\n6 Nadia Conti Event_Communic… sent   Liam Th… recei… 2040-10-08 08:18:00 Liam, …\n\n\nThis final joined table includes:\n\nsender and receiver\ntimestamp (as POSIXct datetime)\ncontent of the intercepted message\ncommunication direction (sent and received tags)\n\nWith this full view, we are now equipped to:\n\nDetect frequently interacting individuals or vessels (Q2a)\nIdentify closely connected groups (Q2b)\nTrace pseudonym usage within message content (Q3a)\n\nIn the next step, we’ll optionally clean up column names and remove any unnecessary fields before saving the output for visual analytics.\n\n\n4.5.8 Join Entity Labels for Sender and Receiver\nTo ensure consistency in naming across our dataset, we extract official labels for all entities. This is particularly useful for handling pseudonyms and identifying duplicate or ambiguous names in later analysis.\n\nentity_labels &lt;- nodes_tbl %&gt;%\n  filter(type == \"Entity\") %&gt;%\n  select(id, label, sub_type)\n\nhead(entity_labels)\n\n# A tibble: 6 × 3\n  id             label          sub_type\n  &lt;chr&gt;          &lt;chr&gt;          &lt;chr&gt;   \n1 Sam            Sam            Person  \n2 Kelly          Kelly          Person  \n3 Nadia Conti    Nadia Conti    Person  \n4 Elise          Elise          Person  \n5 Liam Thorne    Liam Thorne    Person  \n6 Samantha Blake Samantha Blake Person  \n\n\nThis lookup table contains:\n\nid: unique identifier for each person or vessel\nlabel: display name (e.g., “Kelly”, “Samantha Blake”)\nsub_type: further categorizes the entity (e.g., Person, Vessel)\n\nWe will use this to join readable labels to both senders and receivers in our full dataset. This step is essential for:\n\nClarifying who the sender/receiver really is (especially if id is used inconsistently)\nTracking pseudonym usage and overlaps (Q3a)\nBuilding clean visualizations of communication networks (Q2a–b)\n\n\n\n4.5.9 Combine Everything and Save to CSV\nTo finalize the dataset, we enrich the full communication table by joining sender and receiver labels (and types) from the entity_labels lookup. This gives us a human-readable structure, ready for downstream analysis and visualization.\n\ncomm_full &lt;- comm_full %&gt;%\n  left_join(entity_labels, by = c(\"sender\" = \"id\")) %&gt;%\n  rename(sender_label = label, sender_type = sub_type) %&gt;%\n  left_join(entity_labels, by = c(\"receiver\" = \"id\")) %&gt;%\n  rename(receiver_label = label, receiver_type = sub_type)\n\nhead(comm_full)\n\n# A tibble: 6 × 11\n  sender      message_id      type.x receiver type.y timestamp           content\n  &lt;chr&gt;       &lt;chr&gt;           &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;  &lt;dttm&gt;              &lt;chr&gt;  \n1 Sam         Event_Communic… sent   Kelly    recei… 2040-10-05 10:48:00 Hey Ke…\n2 Kelly       Event_Communic… sent   Sam      recei… 2040-10-01 08:13:00 Sam, i…\n3 Kelly       Event_Communic… sent   Sam      recei… 2040-10-07 08:11:00 Hey Sa…\n4 Nadia Conti Event_Communic… sent   Haackle… recei… 2040-10-05 09:45:00 Haackl…\n5 Nadia Conti Event_Communic… sent   Oceanus… recei… 2040-10-05 09:49:00 This i…\n6 Nadia Conti Event_Communic… sent   Liam Th… recei… 2040-10-08 08:18:00 Liam, …\n# ℹ 4 more variables: sender_label &lt;chr&gt;, sender_type &lt;chr&gt;,\n#   receiver_label &lt;chr&gt;, receiver_type &lt;chr&gt;\n\n\nThis results in a clean, consolidated dataset containing:\n\nSender and receiver IDs\nTheir full labels (e.g., “Nadia Conti”)\nTheir types (e.g., Person, Organization)\nTimestamp and message content\n\nFinally, we export the processed dataset to CSV format so it can be reused by the whole team for answering specific questions (Q1, Q2, Q3, Q4).\n\nwrite_csv(comm_full, \"data/communications_full.csv\")\n\nThis communications_full.csv will be the basis for identifying social clusters, alias patterns, and communication dynamics across Oceanus."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#question-2---communication-network-group-detection",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#question-2---communication-network-group-detection",
    "title": "Take-home_Ex02 - VAST Challenge 2025 - Mini Challenge 3",
    "section": "5.1 Question 2 - Communication Network & Group Detection",
    "text": "5.1 Question 2 - Communication Network & Group Detection\nTo answer these two questions, we construct a interactive network graph showing who communicates with whom based on the intercepted radio messages.\nWe use the cleaned comm_full dataset and aggregate all communications into a sender–receiver edge list. Each edge represents at least one message sent from one entity to another. The resulting network allows us to examine the structure and density of interpersonal or inter-organizational interactions.\n\n5.1.1 Visualization\nThis interactive network graph addresses Questions 2a and 2b by uncovering key communication dynamics and community structures within the intercepted message data.\n• Node Labels: Each node is labeled directly on the graph with its name (or pseudonym), allowing for easy identification.\n• Edge Direction: Arrows indicate message flow, showing who sent a message to whom.\n• Node Size: Proportional to the number of messages handled (sent + received). Larger nodes are high-volume communicators and possible influencers or intermediaries.\n• Tooltip Details: Hovering over a node reveals the number of messages sent & received of that node.\n• Node Color & Group Labels: Each node represents an individual or entity, and is colored based on its communication cluster, which is automatically detected using the Louvain community detection algorithm. A cluster refers to a group of nodes that communicate more frequently with each other than with nodes outside their group, which might reflect underlying real-world affiliations or coordinated behavior. From the communication network, five distinct clusters are identified.\n• Filter: Use the “Select by id” dropdown at the top to highlight an individual node along with all entities it communicates with directly.\n• Interactivity: It is possible to zoom in and out the graph to explore dense areas more easily.\n\nCommunication NetworkCode\n\n\n\n\n\n\n\n\n\n\n\nlibrary(igraph)\nlibrary(visNetwork)\nlibrary(dplyr)\n\nedge_list &lt;- comm_full %&gt;%\n  select(sender_label, receiver_label) %&gt;%\n  filter(!is.na(sender_label) & !is.na(receiver_label)) %&gt;%\n  count(sender_label, receiver_label, name = \"weight\")\n\ngraph_comm &lt;- graph_from_data_frame(edge_list, directed = TRUE)\n\n# Step 1: Create igraph object\ngraph_comm &lt;- graph_from_data_frame(edge_list, directed = TRUE)\n\n# Step 2: Louvain Clustering\nclusters &lt;- cluster_walktrap(graph_comm)\n\n# Step 3: Define cluster labels (Cluster 1 to 5)\ncluster_map &lt;- c(\n  \"1\" = \"Cluster 1\",\n  \"2\" = \"Cluster 2\",\n  \"3\" = \"Cluster 3\",\n  \"4\" = \"Cluster 4\",\n  \"5\" = \"Cluster 5\"\n)\n\n# Step 4: Compute node-level info\ndeg_sent &lt;- degree(graph_comm, mode = \"out\")\ndeg_recv &lt;- degree(graph_comm, mode = \"in\")\n\nnodes &lt;- data.frame(\n  id = V(graph_comm)$name,\n  label = V(graph_comm)$name,\n  title = paste0(\"📤 Sent: \", deg_sent, \"&lt;br&gt;📥 Received: \", deg_recv),\n  group = cluster_map[as.character(clusters$membership)],\n  value = deg_sent + deg_recv\n)\n\n# Step 5: Factor group for legend order (Cluster 1 → Cluster 5)\nnodes$group &lt;- factor(nodes$group, levels = paste0(\"Cluster \", 1:5))\n\n# Step 6: Prepare edges\nedges &lt;- data.frame(\n  from = as_edgelist(graph_comm)[, 1],\n  to = as_edgelist(graph_comm)[, 2],\n  arrows = \"to\"\n)\n\n# Step 7: Render interactive graph\nvisNetwork(nodes, edges) %&gt;%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = list(enabled = TRUE)\n  ) %&gt;%\n  visLegend() %&gt;%\n  visPhysics(solver = \"forceAtlas2Based\") %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\n5.1.2 Question 2a - Communication Network: Who Talks to Whom?\n• The largest nodes by size like Mako, Oceanus City Council, and Reef Guardians represent the most active communicators, each with a high total number of messages sent and received. In contrast to these dominant hubs, nodes like Port Security and City Officials participate less frequently, possibly playing supporting roles.\n=&gt; The structure of the communication network is concentrated, with a few dominant communicators and several peripheral participants.This suggests an underlying hierarchy or coordination, potentially reflecting real-world group leadership and operational dynamics.\n• Some entities, such as Mako, primarily receive messages, while others, like The Lookout, mostly send them. However, there are also individuals that are highly active in both sending and receiving messages, such as Nadia Conti, which probably be intermediaries or coordinators among different groups.\n=&gt; The directional patterns assist in identifying influencers or information flow sources, which can be further explored in later clustering (Q2b) and alias tracing (Q3).\n\n\n5.1.3 Question 2b - Group Detection: Who Belongs Together?\nThe communication network reveals five distinct clusters, each representing a group of entities that communicate more frequently within their group/cluster than with outside entities, suggesting likely shared objectives or roles. The clusters were derived using the Louvain algorithm, which detects tightly connected groups within the network. Each cluster is color-coded for visual clarity.\n🔴 Cluster 1 consists of 16 nodes: City Officials, Neptune, Small Fry, Davis, Remora, Mako, V. Miesel Shipping, Rodriguez, Nadia Conti, Elise, Sailor Shifts Team, Knowles, Glitters Team, Osprey, Smantha Blake, and Haacklee Harbor.\n🟢 Cluster 2 consist of 15 nodes: Port Security, Defender, Serenity, Reef Guardian, Seawatch, Horizon, Sentinel, Green Guardians, Himark Harbor, Marlin, Paackland Harbor, Northern Light, Oceanus City Council, EcoVigil, and Liam Thorne.\n🔵 Cluster 3 consists of 6 nodes: The Lookout, The Intern, Mrs. Money, Boss, The Middleman, and The Accountant.\n🟣 Cluster 4 consists of 2 nodes: Sam and Kelly. These two entities barely communicate and, if they do, primarily interact with each other, as their only outside communication is with Cluster 3.\n🟡 Cluster 5 consists of 2 nodes: Miranda Jordan and Clepper Jensen. These two entities barely communicate too and, if they do, only interact with each other. This makes their cluster completely isolated from the broader network, which indicates potential secrecy, independence, or exclusion from main operational flows.\nAs we can see, the network structure is well-organized: most entities belong to well-defined clusters with strong internal communication ties.\nSo what is the dominant focus or topic of communication within each cluster? To explore this, the content of all messages sent or received by members of each group is analyzed. By extracting the top 20 most frequently used keywords per cluster, recurring themes can be identified to better understand the likely roles, concerns, or affiliations of each group within the broader network.\n\n🔴 Cluster 1🟢 Cluster 2🔵 Cluster 3🟣 Cluster 4🟡 Cluster 5Code\n\n\n\n\n# A tibble: 20 × 3\n   cluster word              n\n     &lt;dbl&gt; &lt;chr&gt;         &lt;int&gt;\n 1       1 mako            210\n 2       1 reef            177\n 3       1 nemo            159\n 4       1 equipment       151\n 5       1 remora          142\n 6       1 neptune         128\n 7       1 harbor          119\n 8       1 davis            99\n 9       1 team             98\n10       1 tomorrow         94\n11       1 miesel           80\n12       1 operations       78\n13       1 permit           74\n14       1 operation        69\n15       1 maintain         68\n16       1 crew             65\n17       1 nadia            65\n18       1 protocols        65\n19       1 documentation    63\n20       1 himark           63\n\n\n\n\n\n\n# A tibble: 20 × 3\n   cluster word              n\n     &lt;dbl&gt; &lt;chr&gt;         &lt;int&gt;\n 1       2 reef            427\n 2       2 nemo            310\n 3       2 harbor          201\n 4       2 council         196\n 5       2 city            159\n 6       2 vessels         156\n 7       2 oceanus         141\n 8       2 equipment       131\n 9       2 green           125\n10       2 guardian        125\n11       2 guardians       125\n12       2 sentinel        104\n13       2 environmental   100\n14       2 closure          88\n15       2 vessel           86\n16       2 horizon          85\n17       2 documentation    83\n18       2 himark           79\n19       2 paackland        77\n20       2 monitoring       73\n\n\n\n\n\n\n# A tibble: 20 × 3\n   cluster word             n\n     &lt;dbl&gt; &lt;chr&gt;        &lt;int&gt;\n 1       3 reef           128\n 2       3 nemo           120\n 3       3 money           93\n 4       3 intern          90\n 5       3 meeting         86\n 6       3 lookout         83\n 7       3 conservation    75\n 8       3 boss            61\n 9       3 tomorrow        57\n10       3 middleman       51\n11       3 vessels         44\n12       3 bring           39\n13       3 equipment       35\n14       3 birdwatching    32\n15       3 council         31\n16       3 underwater      26\n17       3 activity        25\n18       3 financial       25\n19       3 increased       25\n20       3 discuss         24\n\n\n\n\n\n\n# A tibble: 20 × 3\n   cluster word             n\n     &lt;dbl&gt; &lt;chr&gt;        &lt;int&gt;\n 1       4 birdwatching    10\n 2       4 lookout          8\n 3       4 reef             8\n 4       4 tomorrow         8\n 5       4 kelly            6\n 6       4 sam              6\n 7       4 conservation     5\n 8       4 nemo             5\n 9       4 hey              4\n10       4 perfect          4\n11       4 rare             4\n12       4 special          4\n13       4 spotted          4\n14       4 vessels          4\n15       4 bring            3\n16       4 crates           3\n17       4 equipment        3\n18       4 fragile          3\n19       4 harbor           3\n20       4 heard            3\n\n\n\n\n\n\n# A tibble: 20 × 3\n   cluster word              n\n     &lt;dbl&gt; &lt;chr&gt;         &lt;int&gt;\n 1       5 miranda          76\n 2       5 equipment        42\n 3       5 clepper          40\n 4       5 jensen           36\n 5       5 environmental    28\n 6       5 vessels          28\n 7       5 conservation     22\n 8       5 documents        20\n 9       5 rodriguez        20\n10       5 document         18\n11       5 harbor           18\n12       5 security         18\n13       5 vessel           18\n14       5 council          16\n15       5 reef             16\n16       5 nemo             14\n17       5 knowles          12\n18       5 meeting          12\n19       5 miesel           12\n20       5 officials        12\n\n\n\n\n\n# Load required libraries\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(igraph)\n\n# Step 1: Extract node-cluster membership from graph\nnode_cluster &lt;- data.frame(\n  label = V(graph_comm)$name,\n  cluster = clusters$membership\n)\n\n# Step 2: Join cluster membership to sender and receiver in comm_full\ncomm_with_cluster &lt;- comm_full %&gt;%\n  left_join(node_cluster, by = c(\"sender_label\" = \"label\")) %&gt;%\n  rename(sender_cluster = cluster) %&gt;%\n  left_join(node_cluster, by = c(\"receiver_label\" = \"label\")) %&gt;%\n  rename(receiver_cluster = cluster)\n\n# Step 3: Convert to long format — one row per message-cluster pair\ncomm_long &lt;- comm_with_cluster %&gt;%\n  select(content, sender_cluster, receiver_cluster) %&gt;%\n  rename(message_content = content) %&gt;%\n  pivot_longer(cols = c(sender_cluster, receiver_cluster),\n               names_to = \"role\", values_to = \"cluster\") %&gt;%\n  filter(!is.na(cluster), !is.na(message_content))\n\n# Step 4: Tokenize text and remove stop words\ndata(\"stop_words\")  # Load tidytext stop word list\n\ntokens_by_cluster &lt;- comm_long %&gt;%\n  unnest_tokens(word, message_content) %&gt;%\n  filter(!word %in% stop_words$word, str_detect(word, \"[a-z]\")) %&gt;%\n  count(cluster, word, sort = TRUE)\n\n# Step 5: Get top 10 keywords per cluster\ntop_keywords &lt;- tokens_by_cluster %&gt;%\n  group_by(cluster) %&gt;%\n  slice_max(n, n = 20, with_ties = FALSE) %&gt;%\n  arrange(cluster, desc(n)) %&gt;%\n  ungroup()\n\n# Step 6: Split into list of data frames by cluster\nkeyword_lists &lt;- top_keywords %&gt;%\n  group_by(cluster) %&gt;%\n  group_split()\n\n# (Optional) Name each list element\nnames(keyword_lists) &lt;- paste0(\"Cluster_\", sort(unique(top_keywords$cluster)))\n\n\n\n\nThese most frequently used keywords in each cluster’s messages reveal the possible focus areas of each group:\n\nCluster 1 appears to be focused on maritime operations. Keywords like “equipment”, “harbor”, “operation(s)”, and “crew” suggest activity around marine logistics, vessel coordination, and technical operations — likely indicating a team involved in sea-based field operations or enforcement.\nCluster 2 centers around regulatory, environmental, and governance topics. Common terms such as “council”, “city”, “guardian(s)”, and “monitoring” suggest this group is tied to regulatory oversight, marine protection, and coastal coordination efforts.\nCluster 3 shows signs of being a coordinating or facilitative cluster. Top words like “meeting”, “tomorrow”, “birdwatching”, and “discuss” suggest involvement in administrative work, strategic planning, or cross-group information flow.\nCluster 4 is characterized by limited communication and does not contain any keywords of significant frequency. This lack of prominent terms makes it difficult to infer any clear thematic focus for the group.\nCluster 5 shows slightly more communication and includes certain frequently used terms. However, its complete isolation from the rest of the network limits contextual interpretation and suggests a potentially detached or non-integrated role."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#question-3---pseudonym-detection-and-usage",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#question-3---pseudonym-detection-and-usage",
    "title": "Take-home_Ex02 - VAST Challenge 2025 - Mini Challenge 3",
    "section": "5.2 Question 3 - Pseudonym Detection and Usage",
    "text": "5.2 Question 3 - Pseudonym Detection and Usage\nTo answer Question 3, this section builds on the earlier visual analytics and introduces new visualizations to examine pseudonym usage in greater detail. A bar chart is generated to show how frequently certain terms are mentioned in communications and a heatmap is generated to show which individuals are using them. These terms include both known pseudonyms identified by Clepper (“Boss” and “The Lookout”) and additional names suspected to be aliases — such as “The Intern,” “The Middleman,” “Mrs. Money,” “The Accountant.” etc. These suspected pseudonyms do not resemble typical personal or organizational names, yet they appear frequently in message content, suggesting they may be informally used aliases.\n\n5.2.1 Visualisation\n\nAdditional VisualizationsCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Load required libraries\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(forcats)\n\n# Step 1: Define list of pseudonym terms (identified + suspected)\npseudonym_terms &lt;- c(\n  \"Boss\", \"The Lookout\", \"The Intern\", \"The Middleman\", \"Mrs. Money\",\n  \"The Accountant\", \"Small Fry\", \"Neptune\", \"Knowles\",\n  \"Mako\", \"Remora\", \"Osprey\", \"Defender\", \"Serenity\", \"Seawatch\", \"Marlin\"\n)\n\n# Step 2: Extract all mentions of pseudonym terms from comm_full\npseudonym_mentions &lt;- comm_full %&gt;%\n  filter(str_detect(content, str_c(pseudonym_terms, collapse = \"|\"))) %&gt;%\n  mutate(\n    mentioned_pseudonym = str_extract_all(content, str_c(pseudonym_terms, collapse = \"|\"))\n  ) %&gt;%\n  unnest(mentioned_pseudonym)\n\n# Step 3a: Plot total mention frequency (Plot 1)\nplot_total &lt;- pseudonym_mentions %&gt;%\n  count(mentioned_pseudonym, sort = TRUE) %&gt;%\n  ggplot(aes(x = reorder(mentioned_pseudonym, n), y = n, fill = n)) +\n  geom_col(show.legend = FALSE) +\n  geom_text(aes(label = n), hjust = -0.2, size = 3.5) +\n  scale_fill_gradient(low = \"#cce5ff\", high = \"#003366\") +\n  coord_flip(clip = \"off\") +\n  labs(\n    title = \"Total Mentions of Identified and Suspected Pseudonyms\",\n    x = \"Pseudonym\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    plot.margin = margin(10, 40, 10, 10)  # right padding to avoid number being clipped\n  )\n\n# Step 3b: Heatmap by sender vs pseudonym (Plot 2)\npseudonym_by_sender &lt;- pseudonym_mentions %&gt;%\n  count(sender_label, mentioned_pseudonym, sort = TRUE)\n\nplot_tile &lt;- ggplot(pseudonym_by_sender, aes(\n  x = fct_reorder(mentioned_pseudonym, desc(n)),\n  y = fct_reorder(sender_label, desc(n)),\n  fill = n)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = ifelse(n &gt; 0, n, \"\")), size = 3, color = \"black\") +\n  scale_fill_gradient(low = \"#f0f9e8\", high = \"#084081\") +\n  labs(\n    title = \"Pseudonym Mentions by Sender (Heatmap View)\",\n    x = \"Pseudonym\",\n    y = \"Sender\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n    axis.text.y = element_text(size = 7),\n    legend.position = \"none\"\n  )\n\n# Step 4: Display both plots\nplot_total\nplot_tile\n\n\n\n\n\n\n5.2.2 Question 3a - Pseudonym Identification & Users: Who Uses What Pseudonyms?\nThe first chart displays how often each suspected pseudonym appears in the intercepted messages. Names like “Mako”, “Neptune”, and “Remora” are mentioned with unusually high frequency. Not only do they appear far more often than most other entities, but their naming style also deviates from conventional personal or organizational names — raising strong suspicions that they may be aliases. Names such as “Mrs. Money”, “The Lookout”, “Boss”, and “The Intern” appear less frequently than the top three, but still much more than the remainings. Their unusual phrasing — resembling roles or nicknames rather than real names — further supports earlier suspicions (including Clepper’s) that they may be pseudonyms used informally in communication. A few other names such as “Serenity”, “The Middleman”, “Marlin”, and “Seawatch” are mentioned less often but still draw attention due to their nonstandard naming format. Despite lower frequency, their distinctiveness suggests they could also serve as aliases.\nThe second visualisation, a heatmap, reveals who is mentioning each pseudonym:\n• “Mako” is mentioned overwhelmingly by “Seawatch”, with a smaller number of references from “The Middleman”.\n• “Neptune” is used most frequently by “The Middleman”, followed closely by “Remora”.\n• “Remora” is most often mentioned by “The Lookout”, with “The Intern” being the next most frequent user.\n• “Mrs. Money” is largely mentioned by “Mako” and “The Intern”, though overall at lower frequencies.\n• “The Lookout” is heavily referenced by both “Remora” and “The Intern”\n• “Boss” is frequently mentioned by “Mrs. Money”, “Samantha Blake”, and “The Middleman”\n• “The Intern” is used most by “The Lookout” and “Remora”\n• “Serenity” is referenced primarily by “Remora”, with some additional mentions by “Mrs. Money”.\n• “The Middleman” is mainly mentioned by “The Intern”, with a few references from “Boss” and “The Lookout”.\n• “Marlin” is mentioned most often by “Remora”, with a smaller number of mentions from “Seawatch”.\n• “Seawatch”, despite being the top user of other pseudonyms like “Mako”, is itself occasionally referenced, mainly by “Remora” and “The Middleman”.\n\n\n5.2.3 Question 3b - How Do Visualizations Aid Pseudonym Investigation?\nThe visualizations make it easier for Clepper to identify common entities by transforming raw message content into frequency-based patterns of term usage. The bar chart highlights oddly named terms that appear unusually frequently, such as “Mako”, “Mrs. Money”, “The Intern”, flagging them as potential aliases based on volume.\nThe heatmap complements this by showing which individuals mention which pseudonyms, helping Clepper see whether a term is repeatedly used by just one person or mentioned by many. This help Clepper narrow down which entities are most closely associated with each pseudonym."
  }
]