{
  "hash": "3eeb05368a360079fbb88b97b5664e5c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take-home_Ex02 - VAST Challenge 2025 - Mini Challenge 3\"\nauthor: \"Hoa Nguyen Phuong\"\nformat:\n  docx: default\ndate-modified: \"last-modified\" \nexecute:\n  echo: true \n  eval: true \n  warning: false \n  freeze: true\n---\n\n\n\n# [1]{style=\"color:mediumvioletred\"} Overview\n\nClepper Jessen, an investigative journalist, is probing potential corruption in Oceanus following the temporary closure of Nemo Reef and the shadowy arrival of pop star Sailor Shift. A knowledge graph constructed from intercepted radio communications offers a detailed map of interactions between people and vessels over the past two weeks. By analyzing these communications — who talks to whom and about what — this report aims to uncover key social groupings, identify individuals using pseudonyms, and uncover hidden networks that may be linked to corruption to support the investigation.\n\n# [2]{style=\"color:mediumvioletred\"} Objective\n\nThis analysis contributes to Mini Challenge 3 by focusing on two key investigative angles: uncovering group structures within the communication network, and identifying individuals who may be hiding behind pseudonyms. The aim is to support Clepper Jessen in understanding how people and vessels are associated—both explicitly and covertly—through intercepted radio communications.\n\nSpecifically, this report addresses:\n\n-   Q2a: Use visual analytics to uncover interactions and relationships between vessels and individuals in the network.\n\n-   Q2b: Identify groups that are closely associated and infer the dominant topics for each.\n\n-   Q3a: Detect the use of pseudonyms within the network and assess which identities those pseudonyms refer to.\n\n-   Q3b: Explain how visual analytics can help reveal common identities hidden behind pseudonyms.\n\nThis submission will constitute the middle part of the team’s Mini Challenge 3 report. The first part (Q1) was completed by Van, focusing on temporal communication patterns. This section, prepared by Hoa, addresses Q2 and Q3a–3b, uncovering key interactions and relationships among individuals and vessels, detecting communication clusters, and identifying pseudonym usage. The final part (Q4 and Reflection) is completed by Summer, who investigates Nadia Conti’s actions and reflects on the overall analytical process.\n\n::: {.callout-note appearance=\"soft\"}\nFor the first part go to [Van’s page](https://isss608-vriadi.netlify.app/take-home_ex/take-home_ex02/take-home_ex02)\n\nFor the last part go to [Summer’s page](../Take-home_Ex02_Summer/index.html)\n:::\n\n# [3]{style=\"color:mediumvioletred\"} Analytical Toolkit: RStudio\n\nAll analysis and visualizations in this report are conducted using RStudio and Quarto, leveraging R’s data wrangling and visualization capabilities. The analysis primarily relies on the `tidyverse` suite for data transformation, and network visualization libraries such as `tidygraph` and `ggraph` to explore entity relationships and communication patterns. These tools enable efficient manipulation of the knowledge graph and the creation of visuals that support pattern recognition and pseudonym detection.\n\nTo ensure reproducibility and a smooth development environment, the following packages are loaded using the `pacman::p_load()` function. If `pacman` is not already installed, it can be added as follows:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\ninstall.packages(\"pacman\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nThe downloaded binary packages are in\n\t/var/folders/nr/x4l8hvc562g81px_9hrd30_r0000gn/T//Rtmpn8rQQL/downloaded_packages\n```\n\n\n:::\n:::\n\n\n\nThen load the necessary libraries:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(\n  tidyverse, tidygraph, ggraph, jsonlite, ggplot2,\n  SmartEDA, lubridate, ggthemes, readr, readxl,\n  knitr, dplyr, visNetwork\n)\n```\n:::\n\n\n\nThese packages provide the foundation for data preparation, exploratory data analysis, and the network-based visual storytelling required to address the challenging questions.\n\n# [4]{style=\"color:mediumvioletred\"} Data\n\nThe dataset used in this analysis is a structured knowledge graph derived from intercepted radio communications on Oceanus over a two-week period. Each node in the graph represents an entity—such as a person, vessel, or pseudonym—while edges represent interactions, such as sending or receiving a message. Edge attributes include timestamps, relationship types, message content, and evidence links. A full breakdown of node types, attributes, and edge semantics is provided in the appendix.\n\nThis dataset provides the foundation for analyzing communication behavior, mapping social structures, and detecting alias usage. It enables us to investigate both explicit and inferred relationships, such as who is speaking to whom, who mentions which vessel, and how pseudonyms like “Boss” or “The Lookout” are embedded in the communication network.\n\n## [4.1]{style=\"color:mediumvioletred\"} Importing Knowledge Graph Data\n\nWe begin by loading the raw knowledge graph and its schema using the `jsonlite` package. The main data file (**MC3_graph.json**) contains two primary components: nodes and edges, which represent entities and their interactions. The accompanying schema file (**MC3_schema.json**) provides structural metadata that helps us understand the types and attributes of each node and edge in the graph.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngraph_data <- fromJSON(\"data/MC3_graph.json\")\nschema_data <- fromJSON(\"data/MC3_schema.json\")\n```\n:::\n\n\n\nThese files form the foundation for all subsequent data wrangling and analysis. In the next steps, we will explore their structure and extract relevant features to support our investigation into entity relationships and pseudonym usage.\n\n## [4.2]{style=\"color:mediumvioletred\"} Inspecting Knowledge Graph Structure\n\nBefore proceeding with data wrangling, we first inspect the structure of the knowledge graph using `glimpse()` to understand the overall layout of nodes and edges.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(graph_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 5\n $ directed  : logi TRUE\n $ multigraph: logi FALSE\n $ graph     :List of 4\n  ..$ mode        : chr \"static\"\n  ..$ edge_default: Named list()\n  ..$ node_default: Named list()\n  ..$ name        : chr \"VAST_MC3_Knowledge_Graph\"\n $ nodes     :'data.frame':\t1159 obs. of  31 variables:\n  ..$ type             : chr [1:1159] \"Entity\" \"Entity\" \"Entity\" \"Entity\" ...\n  ..$ label            : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ name             : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ sub_type         : chr [1:1159] \"Person\" \"Person\" \"Person\" \"Person\" ...\n  ..$ id               : chr [1:1159] \"Sam\" \"Kelly\" \"Nadia Conti\" \"Elise\" ...\n  ..$ timestamp        : chr [1:1159] NA NA NA NA ...\n  ..$ monitoring_type  : chr [1:1159] NA NA NA NA ...\n  ..$ findings         : chr [1:1159] NA NA NA NA ...\n  ..$ content          : chr [1:1159] NA NA NA NA ...\n  ..$ assessment_type  : chr [1:1159] NA NA NA NA ...\n  ..$ results          : chr [1:1159] NA NA NA NA ...\n  ..$ movement_type    : chr [1:1159] NA NA NA NA ...\n  ..$ destination      : chr [1:1159] NA NA NA NA ...\n  ..$ enforcement_type : chr [1:1159] NA NA NA NA ...\n  ..$ outcome          : chr [1:1159] NA NA NA NA ...\n  ..$ activity_type    : chr [1:1159] NA NA NA NA ...\n  ..$ participants     : int [1:1159] NA NA NA NA NA NA NA NA NA NA ...\n  ..$ thing_collected  :'data.frame':\t1159 obs. of  2 variables:\n  .. ..$ type: chr [1:1159] NA NA NA NA ...\n  .. ..$ name: chr [1:1159] NA NA NA NA ...\n  ..$ reference        : chr [1:1159] NA NA NA NA ...\n  ..$ date             : chr [1:1159] NA NA NA NA ...\n  ..$ time             : chr [1:1159] NA NA NA NA ...\n  ..$ friendship_type  : chr [1:1159] NA NA NA NA ...\n  ..$ permission_type  : chr [1:1159] NA NA NA NA ...\n  ..$ start_date       : chr [1:1159] NA NA NA NA ...\n  ..$ end_date         : chr [1:1159] NA NA NA NA ...\n  ..$ report_type      : chr [1:1159] NA NA NA NA ...\n  ..$ submission_date  : chr [1:1159] NA NA NA NA ...\n  ..$ jurisdiction_type: chr [1:1159] NA NA NA NA ...\n  ..$ authority_level  : chr [1:1159] NA NA NA NA ...\n  ..$ coordination_type: chr [1:1159] NA NA NA NA ...\n  ..$ operational_role : chr [1:1159] NA NA NA NA ...\n $ edges     :'data.frame':\t3226 obs. of  5 variables:\n  ..$ id         : chr [1:3226] \"2\" \"3\" \"5\" \"3013\" ...\n  ..$ is_inferred: logi [1:3226] TRUE FALSE TRUE TRUE TRUE TRUE ...\n  ..$ source     : chr [1:3226] \"Sam\" \"Sam\" \"Sam\" \"Sam\" ...\n  ..$ target     : chr [1:3226] \"Relationship_Suspicious_217\" \"Event_Communication_370\" \"Event_Assessment_600\" \"Relationship_Colleagues_430\" ...\n  ..$ type       : chr [1:3226] NA \"sent\" NA NA ...\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(schema_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 1\n $ schema:List of 2\n  ..$ nodes:List of 3\n  .. ..$ Entity      :List of 2\n  .. ..$ Event       :List of 2\n  .. ..$ Relationship:List of 2\n  ..$ edges:List of 3\n  .. ..$ description: chr \"Connections between nodes in the knowledge graph\"\n  .. ..$ is_inferred: chr \"bool\"\n  .. ..$ types      :'data.frame':\t6 obs. of  5 variables:\n```\n\n\n:::\n:::\n\n\n\nThe graph structure contains:\n\n-   1159 nodes, each representing an entity, event, or relationship (Unlike traditional network graphs where nodes represent only entities and edges represent relationships, the VAST Challenge MC3 knowledge graph treats relationships as nodes too.)\n\n-   3226 edges, which describe the connections between these nodes\n\n-   Nodes vary by **type** and **sub_type**, and contain attributes such as **label**, **name**, and a large number of optional fields (e.g., **timestamp**, **content**, **assessment_type**) depending on the node’s **sub_type**\n\nThe schema file describes the expected structure and data types for each node and edge type. It confirms that the dataset follows a consistent schema, but many fields are sparse due to their relevance only to specific node types.\n\nSome observations are:\n\n-   The dataset contains a large number of attributes, but most are sparsely populated, which is expected, as different node types carry different metadata.\n\n-   Communication Event nodes are of particular interest for this analysis, as they contain the message content and timestamps—crucial for exploring interaction patterns, associated groups, and pseudonym usage.\n\n-   Many names appear under label and name fields, including potential aliases. These will need to be cross-checked and standardized for accurate network mapping.\n\nWe will also need to clean and enrich the data by:\n\n-   Converting timestamp fields to datetime\n\n-   Isolating sender-receiver relationships\n\n-   Linking communication content back to referenced entities (e.g., vessels or pseudonyms mentioned)\n\nThese steps are foundational for tracing communication & relationships, uncovering social groups, and identifying pseudonym patterns—all central to answering Questions 2 and 3.\n\n## [4.3]{style=\"color:mediumvioletred\"} Extracting the Edges and Nodes Tables\n\nTo prepare for further analysis, we extract the graph’s nodes and edges components into tidy tibbles. This allows us to explore, filter, and join the data more efficiently using `dplyr` and `tidyverse` tools.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnodes_tbl <- as_tibble(graph_data$nodes)\nedges_tbl <- as_tibble(graph_data$edges)\n\nhead(nodes_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 31\n  type   label   name  sub_type id    timestamp monitoring_type findings content\n  <chr>  <chr>   <chr> <chr>    <chr> <chr>     <chr>           <chr>    <chr>  \n1 Entity Sam     Sam   Person   Sam   <NA>      <NA>            <NA>     <NA>   \n2 Entity Kelly   Kelly Person   Kelly <NA>      <NA>            <NA>     <NA>   \n3 Entity Nadia … Nadi… Person   Nadi… <NA>      <NA>            <NA>     <NA>   \n4 Entity Elise   Elise Person   Elise <NA>      <NA>            <NA>     <NA>   \n5 Entity Liam T… Liam… Person   Liam… <NA>      <NA>            <NA>     <NA>   \n6 Entity Samant… Sama… Person   Sama… <NA>      <NA>            <NA>     <NA>   \n# ℹ 22 more variables: assessment_type <chr>, results <chr>,\n#   movement_type <chr>, destination <chr>, enforcement_type <chr>,\n#   outcome <chr>, activity_type <chr>, participants <int>,\n#   thing_collected <df[,2]>, reference <chr>, date <chr>, time <chr>,\n#   friendship_type <chr>, permission_type <chr>, start_date <chr>,\n#   end_date <chr>, report_type <chr>, submission_date <chr>,\n#   jurisdiction_type <chr>, authority_level <chr>, coordination_type <chr>, …\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(edges_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  id    is_inferred source target                      type \n  <chr> <lgl>       <chr>  <chr>                       <chr>\n1 2     TRUE        Sam    Relationship_Suspicious_217 <NA> \n2 3     FALSE       Sam    Event_Communication_370     sent \n3 5     TRUE        Sam    Event_Assessment_600        <NA> \n4 3013  TRUE        Sam    Relationship_Colleagues_430 <NA> \n5 <NA>  TRUE        Sam    Relationship_Friends_272    <NA> \n6 <NA>  TRUE        Sam    Relationship_Colleagues_215 <NA> \n```\n\n\n:::\n:::\n\n\n\nThe **nodes_tbl** contains 1,159 rows and 31 columns, including attributes like **type**, **label**, **sub_type**, and **content**. Meanwhile, the **edges_tbl** captures 3,226 connections among these nodes, indicating the flow of communication or relationships via **source**, **target**, and **type**.\n\nTo understand the distribution of node types, we generate a quick summary:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(nodes_tbl$type)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n      Entity        Event Relationship \n          72          802          285 \n```\n\n\n:::\n:::\n\n\n\nMost nodes represent Events, which includes communication, assessments, and movements. These are the core of the graph’s activity and will be our main focus moving forward. The remaining nodes represent Relationships (such as colleagues) and Entities (such as people and vessels).\n\nThis breakdown helps guide our filtering in the next steps—particularly in isolating Communication Events and linking them to relevant people, vessels, and aliases for Questions 2 and 3.\n\n## [4.4]{style=\"color:mediumvioletred\"} Initial EDA\n\nTo better understand the characteristics of the dataset, we use the `ExpCatViz()` function from the `SmartEDA` package to examine the distribution of key categorical variables within **nodes_tbl**.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nExpCatViz(data = nodes_tbl, col = \"lightblue\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-1.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[2]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-2.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[3]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-3.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[4]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-4.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[5]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-5.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[6]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-6.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[7]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-7.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[8]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-8.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[9]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-9.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[10]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-10.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[11]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-11.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[12]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-12.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[13]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-13.png)\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n[[14]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-7-14.png)\n:::\n:::\n\n\n\nThis reveals several useful insights:\n\n-   The majority of nodes are of type Event (69%), followed by Relationship (25%) and Entity (6%). This confirms that the dataset is heavily event-driven, reinforcing the need to filter and analyze communication-related events in depth.\n\n-   Most of the categorical fields—such as **monitoring_type**, **assessment_type**, **movement_type**, and **enforcement_type**—are overwhelmingly sparse, with over 90% of values marked as NA. These attributes are subtype-specific and not useful for broad filtering.\n\n-   Variables like **activity_type**, **reference**, **date**, and **time** show close to 100% missingness, suggesting they were either not captured in the graph or only used in a few isolated node types.\n\n-   These early signals reinforce the idea that the most promising and information-rich nodes for analysis are Communication Event nodes, which are expected to contain fields like **content**, **timestamp**, and be connected to both people and vessels.\n\nTo complement our earlier inspection of node attributes, we examine the categorical distribution in the **edges_tbl** using `ExpCatViz()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nExpCatViz(data = edges_tbl, col = \"lightblue\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-8-1.png)\n:::\n:::\n\n\n\nThis reveals the breakdown of type within the edges:\n\n-   The two most frequent edge types are evidence_for (32%) and NA (also 32%). The former indicates that a communication or event node is cited as evidence for another node (typically a relationship or event).\n\n-   **sent** and **received** edges each make up 18% of the total. These are especially important for identifying the flow of communication — i.e., who is sending and who is receiving messages — which will directly support Q2a (interactions) and Q3a (pseudonym tracking).\n\n-   A large number of edge types are marked as NA, which may indicate either missing labels or simple links between nodes (such as connecting a person to a vessel) that don’t fall under a specific relationship category.\n\nThis insight confirms that sent and received edges are essential for reconstructing directed communication paths, while evidence_for edges can later help establish which events support known relationships — a detail that may be helpful in identifying aliases.\n\n## [4.5]{style=\"color:mediumvioletred\"} Data Cleaning and Wrangling\n\nTo analyze interaction & relationships, recognize groups, and identify pseudonym usage, we perform a series of data cleaning and wrangling steps. These steps will allow us to isolate communication events, trace sender–receiver interactions, and prepare a clean dataset for visual exploration.\n\nThe main data preparation steps include:\n\n-   Extracting communication events with timestamps\n\n-   Cleaning and formatting timestamp data\n\n-   Identifying sender and receiver relationships\n\n-   Joining sender-receiver pairs to their respective names\n\n-   Merging all relevant fields into a single tidy dataframe for analysis\n\n-   Saving the cleaned dataset for reuse in subsequent sections\n\n### [4.5.1]{style=\"color:mediumvioletred\"} Extracting Communication Events With Timestamps\n\nThe first step filters out all non-communication events. We focus only on nodes of `type == \"Event\"` and `sub_type == \"Communication\"`, as these contain the actual messages exchanged between people and vessels.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomm_events <- nodes_tbl %>%\n  filter(type == \"Event\", sub_type == \"Communication\")\n\nhead(comm_events)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 31\n  type  label    name  sub_type id    timestamp monitoring_type findings content\n  <chr> <chr>    <chr> <chr>    <chr> <chr>     <chr>           <chr>    <chr>  \n1 Event Communi… <NA>  Communi… Even… 2040-10-… <NA>            <NA>     Hey Th…\n2 Event Communi… <NA>  Communi… Even… 2040-10-… <NA>            <NA>     Hey Th…\n3 Event Communi… <NA>  Communi… Even… 2040-10-… <NA>            <NA>     Sam, i…\n4 Event Communi… <NA>  Communi… Even… 2040-10-… <NA>            <NA>     Mrs. M…\n5 Event Communi… <NA>  Communi… Even… 2040-10-… <NA>            <NA>     Boss, …\n6 Event Communi… <NA>  Communi… Even… 2040-10-… <NA>            <NA>     Mrs. M…\n# ℹ 22 more variables: assessment_type <chr>, results <chr>,\n#   movement_type <chr>, destination <chr>, enforcement_type <chr>,\n#   outcome <chr>, activity_type <chr>, participants <int>,\n#   thing_collected <df[,2]>, reference <chr>, date <chr>, time <chr>,\n#   friendship_type <chr>, permission_type <chr>, start_date <chr>,\n#   end_date <chr>, report_type <chr>, submission_date <chr>,\n#   jurisdiction_type <chr>, authority_level <chr>, coordination_type <chr>, …\n```\n\n\n:::\n:::\n\n\n\nThis gives us a subset of nodes that represent intercepted communications. These records include message content, associated timestamps, and unique IDs that can be matched to senders, receivers, and evidence links.\n\n### [4.5.2]{style=\"color:mediumvioletred\"} Extract Necessary Fields\n\nTo prepare for linking communication events with sender and receiver nodes, we extract only the essential attributes:\n\n-   **id**: unique identifier of each communication event node\n\n-   **timestamp**: the time the message was recorded\n\n-   **content**: the message text, which may contain names, pseudonyms, or references to vessels\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomm_events <- comm_events %>%\n  select(id, timestamp = timestamp, content = content)\n\nhead(comm_events)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  id                    timestamp           content                             \n  <chr>                 <chr>               <chr>                               \n1 Event_Communication_1 2040-10-01 08:09:00 Hey The Intern, it's The Lookout! J…\n2 Event_Communication_2 2040-10-01 08:10:00 Hey The Lookout, The Intern here! I…\n3 Event_Communication_3 2040-10-01 08:13:00 Sam, it's Kelly! Let's meet at Sunr…\n4 Event_Communication_5 2040-10-01 08:16:00 Mrs. Money, it's The Intern. Just c…\n5 Event_Communication_6 2040-10-01 08:19:00 Boss, it's Mrs. Money. I've reviewe…\n6 Event_Communication_7 2040-10-01 08:21:00 Mrs. Money, this is Boss. I'm avail…\n```\n\n\n:::\n:::\n\n\n\nThis step gives us a concise working table with only the fields required for further merging and text analysis. The content column will be particularly important for detecting pseudonyms and identifying entities mentioned in the communication — both of which are key to answering Q2b and Q3a.\n\nIn the next step, we’ll clean and standardize the timestamp to support time-based grouping and visualizations.\n\n### [4.5.3]{style=\"color:mediumvioletred\"} Convert Timestamp from Character to Datetime Format\n\nThe timestamp field was originally stored as a character string. To enable time-based filtering, aggregation, and visualizations, we convert it to proper datetime format using `ymd_hms()` from the `lubridate` package.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomm_events <- comm_events %>%\n  mutate(timestamp = ymd_hms(timestamp))\n\nhead(comm_events)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  id                    timestamp           content                             \n  <chr>                 <dttm>              <chr>                               \n1 Event_Communication_1 2040-10-01 08:09:00 Hey The Intern, it's The Lookout! J…\n2 Event_Communication_2 2040-10-01 08:10:00 Hey The Lookout, The Intern here! I…\n3 Event_Communication_3 2040-10-01 08:13:00 Sam, it's Kelly! Let's meet at Sunr…\n4 Event_Communication_5 2040-10-01 08:16:00 Mrs. Money, it's The Intern. Just c…\n5 Event_Communication_6 2040-10-01 08:19:00 Boss, it's Mrs. Money. I've reviewe…\n6 Event_Communication_7 2040-10-01 08:21:00 Mrs. Money, this is Boss. I'm avail…\n```\n\n\n:::\n:::\n\n\n\nThis transformation ensures that the **timestamp** column is now recognized as a POSIXct object (<dttm>), allowing us to later group communications by hour, day, or time interval.\n\nNext, we’ll move on to identifying sender and receiver connections by working with the **edges_tbl**.\n\n### [4.5.4]{style=\"color:mediumvioletred\"} Filter Edges for Sender and Receiver\n\nTo identify who is sending and receiving each message, we filter the **edges_tbl** to retain only edges of type \"sent\" or \"received\". These indicate a directional connection between an entity (usually a person) and a communication event.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomm_edges <- edges_tbl %>%\n  filter(type %in% c(\"sent\", \"received\")) %>%\n  select(source, target, type)\n\nhead(comm_edges)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  source      target                  type \n  <chr>       <chr>                   <chr>\n1 Sam         Event_Communication_370 sent \n2 Kelly       Event_Communication_3   sent \n3 Kelly       Event_Communication_443 sent \n4 Nadia Conti Event_Communication_331 sent \n5 Nadia Conti Event_Communication_334 sent \n6 Nadia Conti Event_Communication_529 sent \n```\n\n\n:::\n:::\n\n\n\nIn this structure:\n\n-   The **source** column contains the person or entity initiating the edge\n\n-   The **target** column refers to the communication event\n\n-   The **type** column tells us whether this is a sent or received connection\n\nThis step is crucial for establishing sender–receiver pairs in later stages. By reshaping and joining this filtered edge list, we’ll be able to reconstruct the full communication path between individuals — a core component of answering Q2a (interaction mapping) and Q3a (alias tracking).\n\nNext, we’ll reshape this into a wide format with both sender and receiver in the same row.\n\n### [4.5.5]{style=\"color:mediumvioletred\"} Separate and Rename\n\nNext, we break down the filtered **comm_edges** into two separate tables: one for senders and one for receivers. This step allows us to later combine both perspectives of each communication into a single row.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsenders <- comm_edges %>%\n  filter(type == \"sent\") %>%\n  rename(sender = source, message_id = target)\n\nreceivers <- comm_edges %>%\n  filter(type == \"received\") %>%\n  rename(receiver = target, message_id = source)\n```\n:::\n\n\n\n-   In the **senders** table, we treat the source as the person sending the message and the target as the message node (message_id)\n\n-   In the **receivers** table, we flip that: the target is the receiver and the source is the message_id\n\nBy renaming columns consistently, we can later join both tables using the shared **message_id**, giving us a clean structure of:\n\nmessage_id \\| sender \\| receiver\n\nThis format is key to visualizing direct interactions between individuals and spotting recurring patterns in communication and alias usage.\n\n### [4.5.6]{style=\"color:mediumvioletred\"} Join Sender and Receiver Info\n\nNow that we have isolated senders and receivers, we join the two datasets using **message_id** to form a complete sender–receiver pair for each communication event.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomm_pairs <- inner_join(senders, receivers, by = \"message_id\")\nhead(comm_pairs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  sender      message_id              type.x receiver             type.y  \n  <chr>       <chr>                   <chr>  <chr>                <chr>   \n1 Sam         Event_Communication_370 sent   Kelly                received\n2 Kelly       Event_Communication_3   sent   Sam                  received\n3 Kelly       Event_Communication_443 sent   Sam                  received\n4 Nadia Conti Event_Communication_331 sent   Haacklee Harbor      received\n5 Nadia Conti Event_Communication_334 sent   Oceanus City Council received\n6 Nadia Conti Event_Communication_529 sent   Liam Thorne          received\n```\n\n\n:::\n:::\n\n\n\nThe resulting dataframe gives us one row per message, including:\n\n-   sender and receiver names\n\n-   The corresponding message_id\n\n-   Edge types (sent, received) — useful for validating directionality if needed\n\nThis structure is foundational for building a person-to-person interaction network, detecting frequent communication pairs, and identifying clusters of closely associated individuals (Q2b). It also enables us to trace who may be using pseudonyms across multiple interactions (Q3a).\n\nIn the next step, we’ll enrich this structure by joining with the actual communication content and timestamps.\n\n### [4.5.7]{style=\"color:mediumvioletred\"} Combine with Communication Details\n\nTo complete the communication record, we join the sender–receiver pairs with the original message content and timestamps. This creates a single tidy dataset that combines who spoke to whom, when, and what was said.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomm_full <- comm_pairs %>%\n  left_join(comm_events, by = c(\"message_id\" = \"id\"))\n\nhead(comm_full)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 7\n  sender      message_id      type.x receiver type.y timestamp           content\n  <chr>       <chr>           <chr>  <chr>    <chr>  <dttm>              <chr>  \n1 Sam         Event_Communic… sent   Kelly    recei… 2040-10-05 10:48:00 Hey Ke…\n2 Kelly       Event_Communic… sent   Sam      recei… 2040-10-01 08:13:00 Sam, i…\n3 Kelly       Event_Communic… sent   Sam      recei… 2040-10-07 08:11:00 Hey Sa…\n4 Nadia Conti Event_Communic… sent   Haackle… recei… 2040-10-05 09:45:00 Haackl…\n5 Nadia Conti Event_Communic… sent   Oceanus… recei… 2040-10-05 09:49:00 This i…\n6 Nadia Conti Event_Communic… sent   Liam Th… recei… 2040-10-08 08:18:00 Liam, …\n```\n\n\n:::\n:::\n\n\n\nThis final joined table includes:\n\n-   sender and receiver\n\n-   timestamp (as POSIXct datetime)\n\n-   content of the intercepted message\n\n-   communication direction (sent and received tags)\n\nWith this full view, we are now equipped to:\n\n-   Detect frequently interacting individuals or vessels (Q2a)\n\n-   Identify closely connected groups (Q2b)\n\n-   Trace pseudonym usage within message content (Q3a)\n\nIn the next step, we’ll optionally clean up column names and remove any unnecessary fields before saving the output for visual analytics.\n\n### [4.5.8]{style=\"color:mediumvioletred\"} Join Entity Labels for Sender and Receiver\n\nTo ensure consistency in naming across our dataset, we extract official labels for all entities. This is particularly useful for handling pseudonyms and identifying duplicate or ambiguous names in later analysis.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nentity_labels <- nodes_tbl %>%\n  filter(type == \"Entity\") %>%\n  select(id, label, sub_type)\n\nhead(entity_labels)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 3\n  id             label          sub_type\n  <chr>          <chr>          <chr>   \n1 Sam            Sam            Person  \n2 Kelly          Kelly          Person  \n3 Nadia Conti    Nadia Conti    Person  \n4 Elise          Elise          Person  \n5 Liam Thorne    Liam Thorne    Person  \n6 Samantha Blake Samantha Blake Person  \n```\n\n\n:::\n:::\n\n\n\nThis lookup table contains:\n\n-   **id**: unique identifier for each person or vessel\n\n-   **label**: display name (e.g., “Kelly”, “Samantha Blake”)\n\n-   **sub_type**: further categorizes the entity (e.g., Person, Vessel)\n\nWe will use this to join readable labels to both senders and receivers in our full dataset. This step is essential for:\n\n-   Clarifying who the sender/receiver really is (especially if **id** is used inconsistently)\n\n-   Tracking pseudonym usage and overlaps (Q3a)\n\n-   Building clean visualizations of communication networks (Q2a–b)\n\n### [4.5.9]{style=\"color:mediumvioletred\"} Combine Everything and Save to CSV\n\nTo finalize the dataset, we enrich the full communication table by joining sender and receiver labels (and types) from the **entity_labels** lookup. This gives us a human-readable structure, ready for downstream analysis and visualization.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomm_full <- comm_full %>%\n  left_join(entity_labels, by = c(\"sender\" = \"id\")) %>%\n  rename(sender_label = label, sender_type = sub_type) %>%\n  left_join(entity_labels, by = c(\"receiver\" = \"id\")) %>%\n  rename(receiver_label = label, receiver_type = sub_type)\n\nhead(comm_full)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 11\n  sender      message_id      type.x receiver type.y timestamp           content\n  <chr>       <chr>           <chr>  <chr>    <chr>  <dttm>              <chr>  \n1 Sam         Event_Communic… sent   Kelly    recei… 2040-10-05 10:48:00 Hey Ke…\n2 Kelly       Event_Communic… sent   Sam      recei… 2040-10-01 08:13:00 Sam, i…\n3 Kelly       Event_Communic… sent   Sam      recei… 2040-10-07 08:11:00 Hey Sa…\n4 Nadia Conti Event_Communic… sent   Haackle… recei… 2040-10-05 09:45:00 Haackl…\n5 Nadia Conti Event_Communic… sent   Oceanus… recei… 2040-10-05 09:49:00 This i…\n6 Nadia Conti Event_Communic… sent   Liam Th… recei… 2040-10-08 08:18:00 Liam, …\n# ℹ 4 more variables: sender_label <chr>, sender_type <chr>,\n#   receiver_label <chr>, receiver_type <chr>\n```\n\n\n:::\n:::\n\n\n\nThis results in a clean, consolidated dataset containing:\n\n-   Sender and receiver IDs\n\n-   Their full labels (e.g., “Nadia Conti”)\n\n-   Their types (e.g., Person, Organization)\n\n-   Timestamp and message content\n\nFinally, we export the processed dataset to CSV format so it can be reused by the whole team for answering specific questions (Q1, Q2, Q3, Q4).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(comm_full, \"data/communications_full.csv\")\n```\n:::\n\n\n\nThis **communications_full.csv** will be the basis for identifying social clusters, alias patterns, and communication dynamics across Oceanus.\n\n# [5]{style=\"color:mediumvioletred\"} Data Visualization, Observation, and Insights\n\n## [5.1]{style=\"color:mediumvioletred\"} Question 2 - Communication Network & Group Detection\n\nTo answer these two questions, we construct a interactive network graph showing who communicates with whom based on the intercepted radio messages.\n\nWe use the cleaned **comm_full** dataset and aggregate all communications into a sender–receiver edge list. Each edge represents at least one message sent from one entity to another. The resulting network allows us to examine the structure and density of interpersonal or inter-organizational interactions.\n\n### [5.1.1]{style=\"color:mediumvioletred\"} Visualization\n\nThis interactive network graph addresses Questions 2a and 2b by uncovering key communication dynamics and community structures within the intercepted message data.\n\n• Node Labels: Each node is labeled directly on the graph with its name (or pseudonym), allowing for easy identification.\n\n• Edge Direction: Arrows indicate message flow, showing who sent a message to whom.\n\n• Node Size: Proportional to the number of messages handled (sent + received). Larger nodes are high-volume communicators and possible influencers or intermediaries.\n\n• Tooltip Details: Hovering over a node reveals the number of messages sent & received of that node.\n\n• Node Color & Group Labels: Each node represents an individual or entity, and is colored based on its communication cluster, which is automatically detected using the Louvain community detection algorithm. A cluster refers to a group of nodes that communicate more frequently with each other than with nodes outside their group, which might reflect underlying real-world affiliations or coordinated behavior. From the communication network, five distinct clusters are identified.\n\n• Filter: Use the “Select by id” dropdown at the top to highlight an individual node along with all entities it communicates with directly.\n\n• Interactivity: It is possible to zoom in and out the graph to explore dense areas more easily.\n\n::: panel-tabset\n# Communication Network\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-19-1.png)\n:::\n:::\n\n\n\n# Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(igraph)\nlibrary(visNetwork)\nlibrary(dplyr)\n\nedge_list <- comm_full %>%\n  select(sender_label, receiver_label) %>%\n  filter(!is.na(sender_label) & !is.na(receiver_label)) %>%\n  count(sender_label, receiver_label, name = \"weight\")\n\ngraph_comm <- graph_from_data_frame(edge_list, directed = TRUE)\n\n# Step 1: Create igraph object\ngraph_comm <- graph_from_data_frame(edge_list, directed = TRUE)\n\n# Step 2: Louvain Clustering\nclusters <- cluster_walktrap(graph_comm)\n\n# Step 3: Define cluster labels (Cluster 1 to 5)\ncluster_map <- c(\n  \"1\" = \"Cluster 1\",\n  \"2\" = \"Cluster 2\",\n  \"3\" = \"Cluster 3\",\n  \"4\" = \"Cluster 4\",\n  \"5\" = \"Cluster 5\"\n)\n\n# Step 4: Compute node-level info\ndeg_sent <- degree(graph_comm, mode = \"out\")\ndeg_recv <- degree(graph_comm, mode = \"in\")\n\nnodes <- data.frame(\n  id = V(graph_comm)$name,\n  label = V(graph_comm)$name,\n  title = paste0(\"📤 Sent: \", deg_sent, \"<br>📥 Received: \", deg_recv),\n  group = cluster_map[as.character(clusters$membership)],\n  value = deg_sent + deg_recv\n)\n\n# Step 5: Factor group for legend order (Cluster 1 → Cluster 5)\nnodes$group <- factor(nodes$group, levels = paste0(\"Cluster \", 1:5))\n\n# Step 6: Prepare edges\nedges <- data.frame(\n  from = as_edgelist(graph_comm)[, 1],\n  to = as_edgelist(graph_comm)[, 2],\n  arrows = \"to\"\n)\n\n# Step 7: Render interactive graph\nvisNetwork(nodes, edges) %>%\n  visOptions(\n    highlightNearest = TRUE,\n    nodesIdSelection = list(enabled = TRUE)\n  ) %>%\n  visLegend() %>%\n  visPhysics(solver = \"forceAtlas2Based\") %>%\n  visLayout(randomSeed = 123)\n```\n:::\n\n\n:::\n\n### [5.1.2]{style=\"color:mediumvioletred\"} Question 2a - Communication Network: Who Talks to Whom?\n\n• The largest nodes by size like Mako, Oceanus City Council, and Reef Guardians represent the most active communicators, each with a high total number of messages sent and received. In contrast to these dominant hubs, nodes like Port Security and City Officials participate less frequently, possibly playing supporting roles.\n\n=\\> The structure of the communication network is concentrated, with a few dominant communicators and several peripheral participants.This suggests an underlying hierarchy or coordination, potentially reflecting real-world group leadership and operational dynamics.\n\n• Some entities, such as Mako, primarily receive messages, while others, like The Lookout, mostly send them. However, there are also individuals that are highly active in both sending and receiving messages, such as Nadia Conti, which probably be intermediaries or coordinators among different groups.\n\n=\\> The directional patterns assist in identifying influencers or information flow sources, which can be further explored in later clustering (Q2b) and alias tracing (Q3).\n\n### [5.1.3]{style=\"color:mediumvioletred\"} Question 2b - Group Detection: Who Belongs Together?\n\nThe communication network reveals five distinct clusters, each representing a group of entities that communicate more frequently within their group/cluster than with outside entities, suggesting likely shared objectives or roles. The clusters were derived using the Louvain algorithm, which detects tightly connected groups within the network. Each cluster is color-coded for visual clarity.\n\n🔴 Cluster 1 consists of 16 nodes: City Officials, Neptune, Small Fry, Davis, Remora, Mako, V. Miesel Shipping, Rodriguez, Nadia Conti, Elise, Sailor Shifts Team, Knowles, Glitters Team, Osprey, Smantha Blake, and Haacklee Harbor.\n\n🟢 Cluster 2 consist of 15 nodes: Port Security, Defender, Serenity, Reef Guardian, Seawatch, Horizon, Sentinel, Green Guardians, Himark Harbor, Marlin, Paackland Harbor, Northern Light, Oceanus City Council, EcoVigil, and Liam Thorne.\n\n🔵 Cluster 3 consists of 6 nodes: The Lookout, The Intern, Mrs. Money, Boss, The Middleman, and The Accountant.\n\n🟣 Cluster 4 consists of 2 nodes: Sam and Kelly. These two entities barely communicate and, if they do, primarily interact with each other, as their only outside communication is with Cluster 3.\n\n🟡 Cluster 5 consists of 2 nodes: Miranda Jordan and Clepper Jensen. These two entities barely communicate too and, if they do, only interact with each other. This makes their cluster completely isolated from the broader network, which indicates potential secrecy, independence, or exclusion from main operational flows.\n\nAs we can see, the network structure is well-organized: most entities belong to well-defined clusters with strong internal communication ties.\n\nSo what is the dominant focus or topic of communication within each cluster? To explore this, the content of all messages sent or received by members of each group is analyzed. By extracting the top 20 most frequently used keywords per cluster, recurring themes can be identified to better understand the likely roles, concerns, or affiliations of each group within the broader network.\n\n::: panel-tabset\n## 🔴 Cluster 1\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n   cluster word              n\n     <dbl> <chr>         <int>\n 1       1 mako            210\n 2       1 reef            177\n 3       1 nemo            159\n 4       1 equipment       151\n 5       1 remora          142\n 6       1 neptune         128\n 7       1 harbor          119\n 8       1 davis            99\n 9       1 team             98\n10       1 tomorrow         94\n11       1 miesel           80\n12       1 operations       78\n13       1 permit           74\n14       1 operation        69\n15       1 maintain         68\n16       1 crew             65\n17       1 nadia            65\n18       1 protocols        65\n19       1 documentation    63\n20       1 himark           63\n```\n\n\n:::\n:::\n\n\n\n## 🟢 Cluster 2\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n   cluster word              n\n     <dbl> <chr>         <int>\n 1       2 reef            427\n 2       2 nemo            310\n 3       2 harbor          201\n 4       2 council         196\n 5       2 city            159\n 6       2 vessels         156\n 7       2 oceanus         141\n 8       2 equipment       131\n 9       2 green           125\n10       2 guardian        125\n11       2 guardians       125\n12       2 sentinel        104\n13       2 environmental   100\n14       2 closure          88\n15       2 vessel           86\n16       2 horizon          85\n17       2 documentation    83\n18       2 himark           79\n19       2 paackland        77\n20       2 monitoring       73\n```\n\n\n:::\n:::\n\n\n\n## 🔵 Cluster 3\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n   cluster word             n\n     <dbl> <chr>        <int>\n 1       3 reef           128\n 2       3 nemo           120\n 3       3 money           93\n 4       3 intern          90\n 5       3 meeting         86\n 6       3 lookout         83\n 7       3 conservation    75\n 8       3 boss            61\n 9       3 tomorrow        57\n10       3 middleman       51\n11       3 vessels         44\n12       3 bring           39\n13       3 equipment       35\n14       3 birdwatching    32\n15       3 council         31\n16       3 underwater      26\n17       3 activity        25\n18       3 financial       25\n19       3 increased       25\n20       3 discuss         24\n```\n\n\n:::\n:::\n\n\n\n## 🟣 Cluster 4\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n   cluster word             n\n     <dbl> <chr>        <int>\n 1       4 birdwatching    10\n 2       4 lookout          8\n 3       4 reef             8\n 4       4 tomorrow         8\n 5       4 kelly            6\n 6       4 sam              6\n 7       4 conservation     5\n 8       4 nemo             5\n 9       4 hey              4\n10       4 perfect          4\n11       4 rare             4\n12       4 special          4\n13       4 spotted          4\n14       4 vessels          4\n15       4 bring            3\n16       4 crates           3\n17       4 equipment        3\n18       4 fragile          3\n19       4 harbor           3\n20       4 heard            3\n```\n\n\n:::\n:::\n\n\n\n## 🟡 Cluster 5\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n   cluster word              n\n     <dbl> <chr>         <int>\n 1       5 miranda          76\n 2       5 equipment        42\n 3       5 clepper          40\n 4       5 jensen           36\n 5       5 environmental    28\n 6       5 vessels          28\n 7       5 conservation     22\n 8       5 documents        20\n 9       5 rodriguez        20\n10       5 document         18\n11       5 harbor           18\n12       5 security         18\n13       5 vessel           18\n14       5 council          16\n15       5 reef             16\n16       5 nemo             14\n17       5 knowles          12\n18       5 meeting          12\n19       5 miesel           12\n20       5 officials        12\n```\n\n\n:::\n:::\n\n\n\n## Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required libraries\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(igraph)\n\n# Step 1: Extract node-cluster membership from graph\nnode_cluster <- data.frame(\n  label = V(graph_comm)$name,\n  cluster = clusters$membership\n)\n\n# Step 2: Join cluster membership to sender and receiver in comm_full\ncomm_with_cluster <- comm_full %>%\n  left_join(node_cluster, by = c(\"sender_label\" = \"label\")) %>%\n  rename(sender_cluster = cluster) %>%\n  left_join(node_cluster, by = c(\"receiver_label\" = \"label\")) %>%\n  rename(receiver_cluster = cluster)\n\n# Step 3: Convert to long format — one row per message-cluster pair\ncomm_long <- comm_with_cluster %>%\n  select(content, sender_cluster, receiver_cluster) %>%\n  rename(message_content = content) %>%\n  pivot_longer(cols = c(sender_cluster, receiver_cluster),\n               names_to = \"role\", values_to = \"cluster\") %>%\n  filter(!is.na(cluster), !is.na(message_content))\n\n# Step 4: Tokenize text and remove stop words\ndata(\"stop_words\")  # Load tidytext stop word list\n\ntokens_by_cluster <- comm_long %>%\n  unnest_tokens(word, message_content) %>%\n  filter(!word %in% stop_words$word, str_detect(word, \"[a-z]\")) %>%\n  count(cluster, word, sort = TRUE)\n\n# Step 5: Get top 10 keywords per cluster\ntop_keywords <- tokens_by_cluster %>%\n  group_by(cluster) %>%\n  slice_max(n, n = 20, with_ties = FALSE) %>%\n  arrange(cluster, desc(n)) %>%\n  ungroup()\n\n# Step 6: Split into list of data frames by cluster\nkeyword_lists <- top_keywords %>%\n  group_by(cluster) %>%\n  group_split()\n\n# (Optional) Name each list element\nnames(keyword_lists) <- paste0(\"Cluster_\", sort(unique(top_keywords$cluster)))\n```\n:::\n\n\n:::\n\nThese most frequently used keywords in each cluster’s messages reveal the possible focus areas of each group:\n\n-   Cluster 1 appears to be focused on maritime operations. Keywords like “equipment”, \"harbor\", \"operation(s)\", and \"crew\" suggest activity around marine logistics, vessel coordination, and technical operations — likely indicating a team involved in sea-based field operations or enforcement.\n\n-   Cluster 2 centers around regulatory, environmental, and governance topics. Common terms such as “council”, “city”, “guardian(s)”, and \"monitoring\" suggest this group is tied to regulatory oversight, marine protection, and coastal coordination efforts.\n\n-   Cluster 3 shows signs of being a coordinating or facilitative cluster. Top words like “meeting”, \"tomorrow\", “birdwatching”, and \"discuss\" suggest involvement in administrative work, strategic planning, or cross-group information flow.\n\n-   Cluster 4 is characterized by limited communication and does not contain any keywords of significant frequency. This lack of prominent terms makes it difficult to infer any clear thematic focus for the group.\n\n-   Cluster 5 shows slightly more communication and includes certain frequently used terms. However, its complete isolation from the rest of the network limits contextual interpretation and suggests a potentially detached or non-integrated role.\n\n## [5.2]{style=\"color:mediumvioletred\"} Question 3 - Pseudonym Detection and Usage\n\nTo answer Question 3, this section builds on the earlier visual analytics and introduces new visualizations to examine pseudonym usage in greater detail. A bar chart is generated to show how frequently certain terms are mentioned in communications and a heatmap is generated to show which individuals are using them. These terms include both known pseudonyms identified by Clepper (“Boss” and “The Lookout”) and additional names suspected to be aliases — such as “The Intern,” “The Middleman,” “Mrs. Money,” “The Accountant.” etc. These suspected pseudonyms do not resemble typical personal or organizational names, yet they appear frequently in message content, suggesting they may be informally used aliases.\n\n### [5.2.1]{style=\"color:mediumvioletred\"} Visualisation\n\n::: panel-tabset\n## Additional Visualizations\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-27-1.png)\n:::\n\n::: {.cell-output-display}\n![](Take-home_Ex02_files/figure-docx/unnamed-chunk-27-2.png)\n:::\n:::\n\n\n\n## Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load required libraries\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(forcats)\n\n# Step 1: Define list of pseudonym terms (identified + suspected)\npseudonym_terms <- c(\n  \"Boss\", \"The Lookout\", \"The Intern\", \"The Middleman\", \"Mrs. Money\",\n  \"The Accountant\", \"Small Fry\", \"Neptune\", \"Knowles\",\n  \"Mako\", \"Remora\", \"Osprey\", \"Defender\", \"Serenity\", \"Seawatch\", \"Marlin\"\n)\n\n# Step 2: Extract all mentions of pseudonym terms from comm_full\npseudonym_mentions <- comm_full %>%\n  filter(str_detect(content, str_c(pseudonym_terms, collapse = \"|\"))) %>%\n  mutate(\n    mentioned_pseudonym = str_extract_all(content, str_c(pseudonym_terms, collapse = \"|\"))\n  ) %>%\n  unnest(mentioned_pseudonym)\n\n# Step 3a: Plot total mention frequency (Plot 1)\nplot_total <- pseudonym_mentions %>%\n  count(mentioned_pseudonym, sort = TRUE) %>%\n  ggplot(aes(x = reorder(mentioned_pseudonym, n), y = n, fill = n)) +\n  geom_col(show.legend = FALSE) +\n  geom_text(aes(label = n), hjust = -0.2, size = 3.5) +\n  scale_fill_gradient(low = \"#cce5ff\", high = \"#003366\") +\n  coord_flip(clip = \"off\") +\n  labs(\n    title = \"Total Mentions of Identified and Suspected Pseudonyms\",\n    x = \"Pseudonym\",\n    y = \"Frequency\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    plot.margin = margin(10, 40, 10, 10)  # right padding to avoid number being clipped\n  )\n\n# Step 3b: Heatmap by sender vs pseudonym (Plot 2)\npseudonym_by_sender <- pseudonym_mentions %>%\n  count(sender_label, mentioned_pseudonym, sort = TRUE)\n\nplot_tile <- ggplot(pseudonym_by_sender, aes(\n  x = fct_reorder(mentioned_pseudonym, desc(n)),\n  y = fct_reorder(sender_label, desc(n)),\n  fill = n)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = ifelse(n > 0, n, \"\")), size = 3, color = \"black\") +\n  scale_fill_gradient(low = \"#f0f9e8\", high = \"#084081\") +\n  labs(\n    title = \"Pseudonym Mentions by Sender (Heatmap View)\",\n    x = \"Pseudonym\",\n    y = \"Sender\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n    axis.text.y = element_text(size = 7),\n    legend.position = \"none\"\n  )\n\n# Step 4: Display both plots\nplot_total\nplot_tile\n```\n:::\n\n\n:::\n\n### [5.2.2]{style=\"color:mediumvioletred\"} Question 3a - Pseudonym Identification & Users: Who Uses What Pseudonyms?\n\nThe first chart displays how often each suspected pseudonym appears in the intercepted messages. Names like “Mako”, “Neptune”, and “Remora” are mentioned with unusually high frequency. Not only do they appear far more often than most other entities, but their naming style also deviates from conventional personal or organizational names — raising strong suspicions that they may be aliases. Names such as “Mrs. Money”, “The Lookout”, “Boss”, and “The Intern” appear less frequently than the top three, but still much more than the remainings. Their unusual phrasing — resembling roles or nicknames rather than real names — further supports earlier suspicions (including Clepper’s) that they may be pseudonyms used informally in communication. A few other names such as “Serenity”, “The Middleman”, “Marlin”, and “Seawatch” are mentioned less often but still draw attention due to their nonstandard naming format. Despite lower frequency, their distinctiveness suggests they could also serve as aliases.\n\nThe second visualisation, a heatmap, reveals who is mentioning each pseudonym:\n\n• “Mako” is mentioned overwhelmingly by “Seawatch”, with a smaller number of references from “The Middleman”.\n\n• “Neptune” is used most frequently by “The Middleman”, followed closely by “Remora”.\n\n• “Remora” is most often mentioned by “The Lookout”, with “The Intern” being the next most frequent user.\n\n• “Mrs. Money” is largely mentioned by “Mako” and “The Intern”, though overall at lower frequencies.\n\n• “The Lookout” is heavily referenced by both “Remora” and “The Intern”\n\n• “Boss” is frequently mentioned by “Mrs. Money”, “Samantha Blake”, and “The Middleman”\n\n• “The Intern” is used most by “The Lookout” and “Remora”\n\n• “Serenity” is referenced primarily by “Remora”, with some additional mentions by “Mrs. Money”.\n\n• “The Middleman” is mainly mentioned by “The Intern”, with a few references from “Boss” and “The Lookout”.\n\n• “Marlin” is mentioned most often by “Remora”, with a smaller number of mentions from “Seawatch”.\n\n• “Seawatch”, despite being the top user of other pseudonyms like “Mako”, is itself occasionally referenced, mainly by “Remora” and “The Middleman”.\n\n### [5.2.3]{style=\"color:mediumvioletred\"} Question 3b - How Do Visualizations Aid Pseudonym Investigation?\n\nThe visualizations make it easier for Clepper to identify common entities by transforming raw message content into frequency-based patterns of term usage. The bar chart highlights oddly named terms that appear unusually frequently, such as “Mako”, \"Mrs. Money\", \"The Intern\", flagging them as potential aliases based on volume.\n\nThe heatmap complements this by showing which individuals mention which pseudonyms, helping Clepper see whether a term is repeatedly used by just one person or mentioned by many. This help Clepper narrow down which entities are most closely associated with each pseudonym.\n\n# [6]{style=\"color:mediumvioletred\"} Reference\n\n-   VAST 2024 Mini Challenge 3\n-   jsonlite: A robust and high-performance JSON parser and generator for R, useful for working with web APIs and structured data.\n-   tibble: A modern reimagining of data frames in R that prints cleaner and is better for programming.\n-   dplyr: A grammar of data manipulation, making data wrangling concise, fast, and readable.\n-   knitr: A dynamic report generation tool in R, used for rendering markdown reports and tables.\n-   SmartEDA: Automatically generates EDA reports including statistical summaries and visualizations.\n-   lubridate: Simplifies the parsing, manipulation, and extraction of date-time data.\n-   readr: Provides fast and friendly functions for reading and writing rectangular data (e.g., CSV).\n-   ggplot2: A versatile and widely used R package for creating elegant data visualizations based on the Grammar of Graphics.\n-   visNetwork: Enables interactive network visualizations in R using the vis.js JavaScript library.\n-   tidygraph: Provides a tidy framework for network analysis, integrating graph theory with tidy data principles.\n-   ggraph: Extends ggplot2 to visualize network and graph structures with customizable layouts.\n-   ggrepel: Automatically adjusts overlapping text labels in ggplot2 and ggraph visualizations to improve clarity.\n-   tidytext: Provides text mining tools using tidy data principles, including tokenization and word filtering for pseudonym detection.\n\n# [7]{style=\"color:mediumvioletred\"} Appendix\n\nThe following material is provided by the VAST Challenge 2025 MC3 organizers, and outlines how the original knowledge graph was constructed from intercepted radio communications. It illustrates how nodes and relationships were generated from message transcripts, including:\n\n-   How communication nodes were derived from sender/receiver exchanges,\n\n-   How relationship types (e.g., Colleagues) were inferred,\n\n-   And how evidence links between communication and relationships were established.\n\n📝 Note: This reference material is unedited and shown exactly as provided for context purposes.\n\n<iframe src=\"MC3_data_description.pdf\" width=\"100%\" height=\"600px\">\n\nThis browser does not support PDFs. Please download the PDF to view it: <a href=\"MC3_data_description.pdf\">Download PDF</a>\n\n</iframe>\n",
    "supporting": [
      "Take-home_Ex02_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}